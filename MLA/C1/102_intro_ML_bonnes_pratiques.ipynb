{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mon premier classifier (en SK-LEARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEULEMENT AVEC SCIKIT-LEARN\n",
    "# On importe les librairies nécessaires\n",
    "\n",
    "# Le module de datasets de sklearn\n",
    "from sklearn import datasets\n",
    "\n",
    "# Les librairies habituelles\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# On désactive les warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement et formatage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les données de MNIST (incluses dans Keras)\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "label = digits.target\n",
    "data  = digits.data\n",
    "img   = digits.images\n",
    "\n",
    "# On inspecte les dimensions des données \n",
    "print('Dimension des labels:\\n', np.shape(label), '\\n')\n",
    "\n",
    "# On inspecte les dimensions des données \n",
    "print('Dimension des data:\\n', np.shape(data), '\\n')\n",
    "\n",
    "# On inspecte les dimensions des données \n",
    "print('Dimension des images:\\n', np.shape(img), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On trace une image\n",
    "plt.imshow(img[0])\n",
    "plt.show()\n",
    "\n",
    "# On vérifie le label correspondant\n",
    "print('Label de l image:\\n', label[0], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Première version de l'apprentissage : 5-fold "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Organisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe le module SVM (ou autre classifieur)\n",
    "from sklearn import svm\n",
    "\n",
    "# Maintenant on peut utiliser la librairie d'optimisation gridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# On split les données en jeux de train et test (20% de données en test)\n",
    "(data_train, data_test, lbl_train, lbl_test) = train_test_split(data, label, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Déclaration du classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit le jeu de méta-paramètres du classifieur\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "# On définit la grid search\n",
    "clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='accuracy')  #'%s_macro' % score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Apprentissage du classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On apprend le classifieur sur la base d'entrainement\n",
    "clf.fit(data_train, lbl_train)\n",
    "\n",
    "# On print le rapport de l'apprentissage\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Prédiction du classifieur sur la base de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prédit sur la base de test\n",
    "lbl_pred = clf.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Evaluation du classifieur sur la base de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies pour l'évaluation\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# On calcule la matrice de confusion\n",
    "cm_test = confusion_matrix(lbl_test, lbl_pred)\n",
    "print('La matrice de confusion sur le jeu d entrainement :\\n', cm_test, '\\n')\n",
    "\n",
    "# On calcul le score d accuracy\n",
    "acc_train=accuracy_score(lbl_test, lbl_pred)\n",
    "print('L accuracy sur le jeu d entrainement est :\\n', acc_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deuxième version de l'apprentissage : train/test set (défini à la main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Organisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies nécessaires\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "# On split les données en jeux de train et test (20% de données en test)\n",
    "(data_train, data_test, lbl_train, lbl_test) = train_test_split(data, label, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# On créé notre propre split de données pour l'optimisation\n",
    "train_idx     = np.full(len(lbl_train), -1, dtype=int)\n",
    "test_idx      = np.full(len(lbl_test), 1, dtype=int)\n",
    "myFold        = np.append(train_idx, test_idx)\n",
    "ps            = PredefinedSplit(myFold)\n",
    "\n",
    "dataL          = np.vstack((data_train, data_test))\n",
    "labelL         = np.append(lbl_train, lbl_test)\n",
    "\n",
    "# On vérifie combien de split on a créé\n",
    "print('Nombre de splits créé\\n', ps.get_n_splits())\n",
    "\n",
    "print(np.shape(data_train))\n",
    "print(np.shape(data_test))\n",
    "\n",
    "print(np.shape(dataL))\n",
    "print(np.shape(labelL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Déclaration du classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe la librairie SVM (ou autre classifieur)\n",
    "from sklearn import svm\n",
    "\n",
    "# Maintenant on peut utiliser la librairie d'optimisation gridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "# \n",
    "score = 'accuracy'\n",
    "\n",
    "# On apprend le classifier sur les données\n",
    "clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=ps,\n",
    "                       scoring=score)  #'%s_macro' % score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Apprentissage du classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On apprend le classifier sur la base d'entrainement\n",
    "clf.fit(dataL, labelL)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Prédiction du classifieur sur la base de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prédit sur la base de test\n",
    "lbl_pred = clf.predict(data_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Evaluation du classifieur sur la base de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies pour l'évaluation\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# On calcule la matrice de confusion\n",
    "cm_test = confusion_matrix(lbl_test, lbl_pred)\n",
    "print('La matrice de confusion sur le jeu d entrainement :\\n', cm_test, '\\n')\n",
    "\n",
    "# On calcul le score d accuracy\n",
    "acc_train=accuracy_score(lbl_test, lbl_pred)\n",
    "print('L accuracy sur le jeu d entrainement est :\\n', acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## C'EST BEAUCOUP MIEUX!!! :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
