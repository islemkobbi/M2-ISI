{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les réseaux convolutionnels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réseau inspiré de http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement et conditionnement des données d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement et normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La convention pour les images en entrée dans les réseaux de neurones convolutifs en PyTorch est d'utiliser des tenseurs de taille `(batch_size, channels, height, width)`. \n",
    "\n",
    "- `batch_size` correspond au nombre d'images dans un batch\n",
    "- `channels` correspond au nombre de canaux de couleur de l'image. Pour une image en niveaux de gris, `channels` est égal à 1. Pour une image en couleur, `channels` est égal à 3 (rouge, vert, bleu)\n",
    "- `height` correspond à la hauteur de l'image\n",
    "- `width` correspond à la largeur "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Architecture du réseau "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concevoir un réseau inspiré LeNet5 http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf\n",
    "![LeNet5](https://miro.medium.com/max/2000/1*1TI1aGBZ4dybR6__DI9dzA.png)\n",
    "\n",
    "\n",
    "La structure globale sera conservée (nombre de couches, nombre de neurones par couche…) mais dans cette version :\n",
    "- Les couches de convolution sont totalement connectées\n",
    "- La sortie est une couche fully connected (FC) classique \n",
    "- La fonction de coût est l’entropie croisée\n",
    "\n",
    "\n",
    "Vous utiliserez la `nn.Sequential` pour le backbone et vous ajouterez une dernière couche pour la partie classlification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (gc): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (soft_max): Softmax(dim=None)\n",
      "  (relu): ReLU()\n",
      "  (Avg_Pool2d): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, 1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.gc = nn.Linear(84, 10)\n",
    "        self.soft_max = nn.Softmax()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Avg_Pool2d = nn.AvgPool2d(2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.Avg_Pool2d(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.Avg_Pool2d(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.gc(x)\n",
    "        return self.soft_max(x, dim=1)\n",
    "\n",
    "mnist_model = MNISTModel()\n",
    "\n",
    "\n",
    "print(mnist_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apprentissage du réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition des paramètres de l'optimisation (fonction de coût, méthode d'optimisation, hyperparamètres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mnist_model.parameters(), lr=0.05)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boucle d'apprentissage (faire 10 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4096x4 and 400x120)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hp\\Desktop\\M2 ISI\\MLA\\C6\\CNN.ipynb Cell 16\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/M2%20ISI/MLA/C6/CNN.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, targets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/M2%20ISI/MLA/C6/CNN.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/M2%20ISI/MLA/C6/CNN.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     outputs \u001b[39m=\u001b[39m mnist_model(data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/M2%20ISI/MLA/C6/CNN.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# converti automatiquement les labels dans targets en vecteur one hot\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/M2%20ISI/MLA/C6/CNN.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\hp\\Desktop\\M2 ISI\\MLA\\C6\\CNN.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/M2%20ISI/MLA/C6/CNN.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/M2%20ISI/MLA/C6/CNN.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mAvg_Pool2d(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/M2%20ISI/MLA/C6/CNN.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/M2%20ISI/MLA/C6/CNN.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/M2%20ISI/MLA/C6/CNN.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgc(x)\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4096x4 and 400x120)"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mnist_model(data)\n",
    "        # converti automatiquement les labels dans targets en vecteur one hot\n",
    "        loss = criterion(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    #loss calculé uniquement sur le dernier batch de l'epoch\n",
    "    print('epoch {}: {} (last batch)'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation du modèle sur la base de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On visualise le resultat pour `b_size` images et on les compare à la vérité terrain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data, target = next(iter(test_loader))\n",
    "b_size = 5\n",
    "data = test_loader.dataset.data[0:b_size].data.unsqueeze(1).float()\n",
    "target = test_loader.dataset.targets[0:b_size]\n",
    "pred = mnist_model(data)\n",
    "print(pred.argmax(dim=1, keepdim=False))\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On évalue les performances sur l'ensemble des données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "# pour ne aps calculer les gradients (gain de temps et de mémoire)\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = mnist_model(data)\n",
    "        test_loss += criterion(output, target).item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisation des filtres appris par le réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ecrire une fonction de visualisation des filtres avec la signature suivante :  \n",
    "`displayConvFilers(model, layer_name, num_filter=4, filter_size=(3,3), num_channel=0, fig_size=(2,2))`\n",
    "- `model` : le réseau de neurones dont on souhaite visualiser les filtres\n",
    "- `layer_name` : le nom de la couche dont on souhaite visualiser les filtres \n",
    "- `num_channel` : le numéro du canal dont on souhaite visualiser les filtres\n",
    "- `fig_size` : les dimensions de la figure. Doivent être en cohérence avec le nombre de filtres de la couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afficher la liste des noms des couches\n",
    "filters = mnist_model.state_dict()\n",
    "print(filters.keys())\n",
    "\n",
    "#Pour récupérer les poids de la première couche\n",
    "filters  = mnist_model.state_dict()['lenet5_backbone.0.weight']\n",
    "filters.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ces noms peuvent se déduire de l'affichage de la structure du réseau\n",
    "print(mnist_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayConvFilters(model, layer_name, num_channel=0, fig_size=(2,2)):\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appeler deux fois la fonction pour afficher les filtres de la première couche et le premier canal des filtres de la deuxième couche de convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
