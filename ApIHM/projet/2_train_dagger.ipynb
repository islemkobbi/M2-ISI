{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[download this notebook here](https://github.com/HumanCompatibleAI/imitation/blob/master/docs/tutorials/2_train_dagger.ipynb)\n",
    "# Train an Agent using the DAgger Algorithm\n",
    "\n",
    "The DAgger algorithm is an extension of behavior cloning. \n",
    "In behavior cloning, the training trajectories are recorded directly from an expert.\n",
    "In DAgger, the learner generates the trajectories but an expert corrects the actions with the optimal actions in each of the visited states.\n",
    "This ensures that the state distribution of the training data matches that of the learner's current policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need an expert to learn from. For convenience we download one from the HuggingFace model hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kobbi\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:166: UserWarning: Could not deserialize object learning_rate. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code() argument 13 must be str, not int\n",
      "  warnings.warn(\n",
      "c:\\Users\\kobbi\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:166: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code() argument 13 must be str, not int\n",
      "  warnings.warn(\n",
      "c:\\Users\\kobbi\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code() argument 13 must be str, not int\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from imitation.policies.serialize import load_policy\n",
    "from imitation.util.util import make_vec_env\n",
    "\n",
    "env = make_vec_env(\n",
    "    \"seals:seals/CartPole-v0\",\n",
    "    rng=np.random.default_rng(),\n",
    "    n_envs=1,\n",
    ")\n",
    "expert = load_policy(\n",
    "    \"ppo-huggingface\",\n",
    "    organization=\"HumanCompatibleAI\",\n",
    "    env_name=\"seals/CartPole-v0\",\n",
    "    venv=env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "from imitation.algorithms import bc\n",
    "from imitation.algorithms.dagger import SimpleDAggerTrainer\n",
    "\n",
    "bc_trainer = bc.BC(\n",
    "    observation_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    rng=np.random.default_rng(),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can construct a DAgger trainer und use it to train the policy on the cartpole environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kobbi\\AppData\\Local\\Temp\\dagger_example_6gpjs575\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de77a0a429f24a3a885b89491907e707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7149db1bf54c4b839d1535e965b16570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206ee7029c744a998ecb292cf18c07fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 0         |\n",
      "|    ent_loss       | -0.000693 |\n",
      "|    entropy        | 0.693     |\n",
      "|    epoch          | 0         |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 72.5      |\n",
      "|    loss           | 0.692     |\n",
      "|    neglogp        | 0.692     |\n",
      "|    prob_true_act  | 0.5       |\n",
      "|    samples_so_far | 32        |\n",
      "| rollout/          |           |\n",
      "|    return_max     | 23        |\n",
      "|    return_mean    | 16.8      |\n",
      "|    return_min     | 9         |\n",
      "|    return_std     | 4.75      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184batch [00:01, 118.11batch/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6379360293e440d985845d860c8c2262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6aad5cbf6f451385a2edd4a79804e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fa0a23eae04018a78a168e051a3f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| batch_size        | 32       |\n",
      "| bc/               |          |\n",
      "|    batch          | 0        |\n",
      "|    ent_loss       | -0.00032 |\n",
      "|    entropy        | 0.32     |\n",
      "|    epoch          | 0        |\n",
      "|    l2_loss        | 0        |\n",
      "|    l2_norm        | 86.9     |\n",
      "|    loss           | 0.313    |\n",
      "|    neglogp        | 0.313    |\n",
      "|    prob_true_act  | 0.781    |\n",
      "|    samples_so_far | 32       |\n",
      "| rollout/          |          |\n",
      "|    return_max     | 135      |\n",
      "|    return_mean    | 97.6     |\n",
      "|    return_min     | 72       |\n",
      "|    return_std     | 23.5     |\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "372batch [00:01, 195.14batch/s]\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "from imitation.algorithms import bc\n",
    "from imitation.algorithms.dagger import SimpleDAggerTrainer\n",
    "\n",
    "bc_trainer = bc.BC(\n",
    "    observation_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    rng=np.random.default_rng(),\n",
    ")\n",
    "\n",
    "with tempfile.TemporaryDirectory(prefix=\"dagger_example_\") as tmpdir:\n",
    "    print(tmpdir)\n",
    "    dagger_trainer = SimpleDAggerTrainer(\n",
    "        venv=env,\n",
    "        scratch_dir=tmpdir,\n",
    "        expert_policy=expert,\n",
    "        bc_trainer=bc_trainer,\n",
    "        rng=np.random.default_rng(),\n",
    "    )\n",
    "\n",
    "    dagger_trainer.train(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the evaluation shows, that we actually trained a policy that solves the environment (500 is the max reward)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "reward, _ = evaluate_policy(dagger_trainer.policy, env, 20)\n",
    "print(reward)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd378ce8f53beae712f05342da42c6a7612fc68b19bea03b52c7b1cdc8851b5f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
